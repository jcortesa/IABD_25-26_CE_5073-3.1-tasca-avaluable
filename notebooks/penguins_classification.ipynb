{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7105c9",
   "metadata": {},
   "source": [
    "## 1. Càrrega de Llibreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbd4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llibreries de dades\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Llibreries de Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Serialització\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Configuració de visualització\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b506f",
   "metadata": {},
   "source": [
    "## 2. Càrrega i Exploració de les Dades (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5918130",
   "metadata": {},
   "source": [
    "### 2.1 Carregar el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c3232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregat amb 344 files i 7 columnes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>195.0</td>\n",
       "      <td>4675.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>34.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "6  Adelie  Torgersen            38.9           17.8              181.0   \n",
       "7  Adelie  Torgersen            39.2           19.6              195.0   \n",
       "8  Adelie  Torgersen            34.1           18.1              193.0   \n",
       "9  Adelie  Torgersen            42.0           20.2              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  \n",
       "6       3625.0  Female  \n",
       "7       4675.0    Male  \n",
       "8       3475.0     NaN  \n",
       "9       4250.0     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar dataset des de Seaborn\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Mostrar primeres files\n",
    "print(f\"Dataset carregat amb {len(df)} files i {len(df.columns)} columnes\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf2d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "INFORMACIÓ DEL DATASET\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informació del dataset\n",
    "print(\"=\"*50)\n",
    "print(\"INFORMACIÓ DEL DATASET\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff9a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ESTADÍSTIQUES DESCRIPTIVES\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.921930</td>\n",
       "      <td>17.151170</td>\n",
       "      <td>200.915205</td>\n",
       "      <td>4201.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.459584</td>\n",
       "      <td>1.974793</td>\n",
       "      <td>14.061714</td>\n",
       "      <td>801.954536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.225000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.450000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "count      342.000000     342.000000         342.000000   342.000000\n",
       "mean        43.921930      17.151170         200.915205  4201.754386\n",
       "std          5.459584       1.974793          14.061714   801.954536\n",
       "min         32.100000      13.100000         172.000000  2700.000000\n",
       "25%         39.225000      15.600000         190.000000  3550.000000\n",
       "50%         44.450000      17.300000         197.000000  4050.000000\n",
       "75%         48.500000      18.700000         213.000000  4750.000000\n",
       "max         59.600000      21.500000         231.000000  6300.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estadístiques descriptives\n",
    "print(\"=\"*50)\n",
    "print(\"ESTADÍSTIQUES DESCRIPTIVES\")\n",
    "print(\"=\"*50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba66664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DISTRIBUCIÓ D'ESPÈCIES\n",
      "==================================================\n",
      "species\n",
      "Adelie       152\n",
      "Gentoo       124\n",
      "Chinstrap     68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proporció:\n",
      "species\n",
      "Adelie       0.442\n",
      "Gentoo       0.360\n",
      "Chinstrap    0.198\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Distribució de la variable objectiu (species)\n",
    "print(\"=\"*50)\n",
    "print(\"DISTRIBUCIÓ D'ESPÈCIES\")\n",
    "print(\"=\"*50)\n",
    "print(df['species'].value_counts())\n",
    "print(\"\\nProporció:\")\n",
    "print(df['species'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4020c43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VALORS NULS PER COLUMNA\n",
      "==================================================\n",
      "species               0\n",
      "island                0\n",
      "bill_length_mm        2\n",
      "bill_depth_mm         2\n",
      "flipper_length_mm     2\n",
      "body_mass_g           2\n",
      "sex                  11\n",
      "dtype: int64\n",
      "\n",
      "Total de files amb algun valor nul: 11\n",
      "Total de files: 344\n"
     ]
    }
   ],
   "source": [
    "# Valors nuls\n",
    "print(\"=\"*50)\n",
    "print(\"VALORS NULS PER COLUMNA\")\n",
    "print(\"=\"*50)\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)\n",
    "print(f\"\\nTotal de files amb algun valor nul: {df.isnull().any(axis=1).sum()}\")\n",
    "print(f\"Total de files: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a48ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VALORS ÚNICS DE VARIABLES CATEGÒRIQUES\n",
      "==================================================\n",
      "species: ['Adelie', 'Chinstrap', 'Gentoo']\n",
      "island: ['Torgersen', 'Biscoe', 'Dream']\n",
      "sex: ['Male', 'Female']\n"
     ]
    }
   ],
   "source": [
    "# Valors únics de columnes categòriques (important per al client!)\n",
    "print(\"=\"*50)\n",
    "print(\"VALORS ÚNICS DE VARIABLES CATEGÒRIQUES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"species: {df['species'].unique().tolist()}\")\n",
    "print(f\"island: {df['island'].unique().tolist()}\")\n",
    "print(f\"sex: {df['sex'].dropna().unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f921af",
   "metadata": {},
   "source": [
    "## 3. Preprocessament de les Dades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27295495",
   "metadata": {},
   "source": [
    "### 3.1 Eliminar files amb valors nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f47116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files originals: 344\n",
      "Files després d'eliminar NA: 333\n",
      "Files eliminades: 11\n",
      "\n",
      "Valors nuls restants: 0\n"
     ]
    }
   ],
   "source": [
    "# Eliminar files amb NA\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(f\"Files originals: {len(df)}\")\n",
    "print(f\"Files després d'eliminar NA: {len(df_clean)}\")\n",
    "print(f\"Files eliminades: {len(df) - len(df_clean)}\")\n",
    "\n",
    "# Verificar que no queden valors nuls\n",
    "print(f\"\\nValors nuls restants: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9593442",
   "metadata": {},
   "source": [
    "### 3.2 Separar features i target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6825b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables predictores (features):\n",
      "  Categòriques: ['island', 'sex']\n",
      "  Numèriques: ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
      "\n",
      "Variable objectiu: species\n",
      "\n",
      "Forma de X: (333, 6)\n",
      "Forma de y: (333,)\n"
     ]
    }
   ],
   "source": [
    "# Separar features (X) i target (y)\n",
    "X = df_clean.drop('species', axis=1)\n",
    "y = df_clean['species']\n",
    "\n",
    "# Definir variables categòriques i numèriques\n",
    "cat_cols = ['island', 'sex']\n",
    "num_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "print(\"Variables predictores (features):\")\n",
    "print(f\"  Categòriques: {cat_cols}\")\n",
    "print(f\"  Numèriques: {num_cols}\")\n",
    "print(f\"\\nVariable objectiu: species\")\n",
    "print(f\"\\nForma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c78bc",
   "metadata": {},
   "source": [
    "### 3.3 Divisió Train/Test (80/20)\n",
    "\n",
    "**IMPORTANT:** La divisió es fa ABANS del preprocessament per evitar data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833fbdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisió Train/Test:\n",
      "  Train: 266 mostres (79.9%)\n",
      "  Test: 67 mostres (20.1%)\n",
      "\n",
      "Distribució d'espècies en Train:\n",
      "species\n",
      "Adelie       117\n",
      "Gentoo        95\n",
      "Chinstrap     54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribució d'espècies en Test:\n",
      "species\n",
      "Adelie       29\n",
      "Gentoo       24\n",
      "Chinstrap    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Divisió 80/20 ABANS de preprocessar (evitar data leakage!)\n",
    "# stratify=y manté les proporcions d'espècies en train i test\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Divisió Train/Test:\")\n",
    "print(f\"  Train: {X_train_raw.shape[0]} mostres ({X_train_raw.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test: {X_test_raw.shape[0]} mostres ({X_test_raw.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDistribució d'espècies en Train:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nDistribució d'espècies en Test:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfdecdf",
   "metadata": {},
   "source": [
    "### 3.4 Codificació One-Hot (DictVectorizer)\n",
    "\n",
    "Utilitzem `DictVectorizer` per convertir les variables categòriques en format one-hot. \n",
    "**Important:** Fem `fit()` només sobre el conjunt d'entrenament!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19cbe613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnes generades pel DictVectorizer:\n",
      "['island=Biscoe' 'island=Dream' 'island=Torgersen' 'sex=Female' 'sex=Male']\n",
      "\n",
      "Forma X_train_cat: (266, 5)\n",
      "Forma X_test_cat: (67, 5)\n"
     ]
    }
   ],
   "source": [
    "# Codificació one-hot amb DictVectorizer (fit només sobre train!)\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Convertir a diccionari i aplicar DictVectorizer\n",
    "X_train_cat = dv.fit_transform(X_train_raw[cat_cols].to_dict(orient='records'))\n",
    "X_test_cat = dv.transform(X_test_raw[cat_cols].to_dict(orient='records'))\n",
    "\n",
    "print(\"Columnes generades pel DictVectorizer:\")\n",
    "print(dv.get_feature_names_out())\n",
    "print(f\"\\nForma X_train_cat: {X_train_cat.shape}\")\n",
    "print(f\"Forma X_test_cat: {X_test_cat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead3467",
   "metadata": {},
   "source": [
    "### 3.5 Normalització (StandardScaler)\n",
    "\n",
    "Apliquem `StandardScaler` a les variables numèriques per estandarditzar-les (mitjana=0, desviació=1).\n",
    "**Important:** Fem `fit()` només sobre el conjunt d'entrenament!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77719597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadístiques del Scaler (calculades sobre train):\n",
      "  Mitjanes: [  43.98   17.23  201.3  4224.44]\n",
      "  Desviacions: [  5.47   1.97  14.01 808.91]\n",
      "\n",
      "Forma X_train_num: (266, 4)\n",
      "Forma X_test_num: (67, 4)\n"
     ]
    }
   ],
   "source": [
    "# Normalització estàndard (fit només sobre train!)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num = scaler.fit_transform(X_train_raw[num_cols])\n",
    "X_test_num = scaler.transform(X_test_raw[num_cols])\n",
    "\n",
    "print(\"Estadístiques del Scaler (calculades sobre train):\")\n",
    "print(f\"  Mitjanes: {scaler.mean_.round(2)}\")\n",
    "print(f\"  Desviacions: {scaler.scale_.round(2)}\")\n",
    "print(f\"\\nForma X_train_num: {X_train_num.shape}\")\n",
    "print(f\"Forma X_test_num: {X_test_num.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d7325e",
   "metadata": {},
   "source": [
    "### 3.6 Combinar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eafc4dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RESUM DEL PREPROCESSAMENT\n",
      "==================================================\n",
      "Forma final X_train: (266, 9)\n",
      "Forma final X_test: (67, 9)\n",
      "Forma y_train: (266,)\n",
      "Forma y_test: (67,)\n",
      "\n",
      "Total de features: 9\n",
      "  - Features categòriques (one-hot): 5\n",
      "  - Features numèriques: 4\n"
     ]
    }
   ],
   "source": [
    "# Combinar features categòriques i numèriques\n",
    "X_train = np.hstack([X_train_cat, X_train_num])\n",
    "X_test = np.hstack([X_test_cat, X_test_num])\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"RESUM DEL PREPROCESSAMENT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Forma final X_train: {X_train.shape}\")\n",
    "print(f\"Forma final X_test: {X_test.shape}\")\n",
    "print(f\"Forma y_train: {y_train.shape}\")\n",
    "print(f\"Forma y_test: {y_test.shape}\")\n",
    "print(f\"\\nTotal de features: {X_train.shape[1]}\")\n",
    "print(f\"  - Features categòriques (one-hot): {X_train_cat.shape[1]}\")\n",
    "print(f\"  - Features numèriques: {X_train_num.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156d729",
   "metadata": {},
   "source": [
    "## 4. Entrenament dels Models\n",
    "\n",
    "Entrenarem 4 models de classificació:\n",
    "1. **Regressió Logística**\n",
    "2. **SVM (Support Vector Machine)**\n",
    "3. **Arbres de Decisió**\n",
    "4. **KNN (K-Nearest Neighbors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fcbc61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL: LOGISTIC_REGRESSION\n",
      "============================================================\n",
      "\n",
      "Accuracy: 0.9851 (98.51%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      0.97      0.98        29\n",
      "   Chinstrap       0.93      1.00      0.97        14\n",
      "      Gentoo       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.99        67\n",
      "   macro avg       0.98      0.99      0.98        67\n",
      "weighted avg       0.99      0.99      0.99        67\n",
      "\n",
      "\n",
      "============================================================\n",
      "MODEL: SVM\n",
      "============================================================\n",
      "\n",
      "Accuracy: 1.0000 (100.00%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      1.00      1.00        29\n",
      "   Chinstrap       1.00      1.00      1.00        14\n",
      "      Gentoo       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        67\n",
      "   macro avg       1.00      1.00      1.00        67\n",
      "weighted avg       1.00      1.00      1.00        67\n",
      "\n",
      "\n",
      "============================================================\n",
      "MODEL: DECISION_TREE\n",
      "============================================================\n",
      "\n",
      "Accuracy: 0.9254 (92.54%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.93      0.90      0.91        29\n",
      "   Chinstrap       0.82      1.00      0.90        14\n",
      "      Gentoo       1.00      0.92      0.96        24\n",
      "\n",
      "    accuracy                           0.93        67\n",
      "   macro avg       0.92      0.94      0.92        67\n",
      "weighted avg       0.93      0.93      0.93        67\n",
      "\n",
      "\n",
      "============================================================\n",
      "MODEL: KNN\n",
      "============================================================\n",
      "\n",
      "Accuracy: 0.9851 (98.51%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      0.97      0.98        29\n",
      "   Chinstrap       0.93      1.00      0.97        14\n",
      "      Gentoo       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.99        67\n",
      "   macro avg       0.98      0.99      0.98        67\n",
      "weighted avg       0.99      0.99      0.99        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir els 4 models\n",
    "models = {\n",
    "    'logistic_regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'svm': SVC(kernel='rbf', random_state=42),\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=42),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Entrenar i avaluar cada model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MODEL: {name.upper()}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Entrenar\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predir\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Avaluar\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770b337",
   "metadata": {},
   "source": [
    "### Resum de Resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0be10278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUM COMPARATIU DELS MODELS\n",
      "============================================================\n",
      "              Model  Accuracy  Accuracy %\n",
      "                svm  1.000000      100.00\n",
      "logistic_regression  0.985075       98.51\n",
      "                knn  0.985075       98.51\n",
      "      decision_tree  0.925373       92.54\n",
      "\n",
      "✓ Millor model: svm amb 100.00% d'accuracy\n"
     ]
    }
   ],
   "source": [
    "# Resum comparatiu dels models\n",
    "print(\"=\"*60)\n",
    "print(\"RESUM COMPARATIU DELS MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': list(results.values())\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "results_df['Accuracy %'] = (results_df['Accuracy'] * 100).round(2)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Millor model\n",
    "best_model = results_df.iloc[0]['Model']\n",
    "best_accuracy = results_df.iloc[0]['Accuracy']\n",
    "print(f\"\\n✓ Millor model: {best_model} amb {best_accuracy*100:.2f}% d'accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a34f0",
   "metadata": {},
   "source": [
    "## 5. Serialització dels Models amb Pickle\n",
    "\n",
    "Guardarem els 4 models entrenats i els preprocessadors (DictVectorizer i StandardScaler) per poder-los utilitzar al servidor Flask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5aa7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model guardat: ../models/logistic_regression.pck\n",
      "✓ Model guardat: ../models/svm.pck\n",
      "✓ Model guardat: ../models/decision_tree.pck\n",
      "✓ Model guardat: ../models/knn.pck\n",
      "✓ DictVectorizer guardat: ../models/dict_vectorizer.pck\n",
      "✓ StandardScaler guardat: ../models/scaler.pck\n",
      "\n",
      "==================================================\n",
      "SERIALITZACIÓ COMPLETADA\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Crear directori models si no existeix (ruta relativa des de notebooks/)\n",
    "MODELS_PATH = '../models'\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# Guardar els 4 models\n",
    "for name, model in models.items():\n",
    "    filepath = f'{MODELS_PATH}/{name}.pck'\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"✓ Model guardat: {filepath}\")\n",
    "\n",
    "# Guardar preprocessadors (IMPORTANT per fer prediccions!)\n",
    "with open(f'{MODELS_PATH}/dict_vectorizer.pck', 'wb') as f:\n",
    "    pickle.dump(dv, f)\n",
    "print(f\"✓ DictVectorizer guardat: {MODELS_PATH}/dict_vectorizer.pck\")\n",
    "\n",
    "with open(f'{MODELS_PATH}/scaler.pck', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"✓ StandardScaler guardat: {MODELS_PATH}/scaler.pck\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SERIALITZACIÓ COMPLETADA\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ac6bb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitxers al directori models/:\n",
      "  logistic_regression.pck: 966 bytes\n",
      "  knn.pck: 27249 bytes\n",
      "  svm.pck: 5586 bytes\n",
      "  decision_tree.pck: 3217 bytes\n",
      "  dict_vectorizer.pck: 307 bytes\n",
      "  scaler.pck: 700 bytes\n"
     ]
    }
   ],
   "source": [
    "# Verificar els fitxers guardats\n",
    "print(\"Fitxers al directori models/:\")\n",
    "for f in os.listdir(MODELS_PATH):\n",
    "    filepath = f'{MODELS_PATH}/{f}'\n",
    "    size = os.path.getsize(filepath)\n",
    "    print(f\"  {f}: {size} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (penguins-classification)",
   "language": "python",
   "name": "penguins-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
